{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c5237-f4e5-4777-ba84-22fc3d46509e",
   "metadata": {
    "executionInfo": {
     "elapsed": 5150,
     "status": "ok",
     "timestamp": 1744557141101,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "9d9c5237-f4e5-4777-ba84-22fc3d46509e"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import keras\n",
    "import numpy as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b105f-03ea-4533-b0ce-35a5931c793b",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744557141102,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "b62b105f-03ea-4533-b0ce-35a5931c793b"
   },
   "outputs": [],
   "source": [
    "# pre process data from dataset\n",
    "with open(\"manocheri_lyric.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "# seprate each mesra'\n",
    "data = data.replace(\"#\", \"\\n#\")\n",
    "corpus = data.split(\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e218fd-cc96-4fb5-ba53-53bda8a72fbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1857,
     "status": "ok",
     "timestamp": 1744557142952,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "b8e218fd-cc96-4fb5-ba53-53bda8a72fbf",
    "outputId": "15b592e6-7a7a-4db8-c98c-36cba187fa32",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tokenize the text and take numper of words\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_word = len(tokenizer.word_index) + 1\n",
    "print(total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2550f8-1f35-432e-96de-027cff592bdd",
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1744557142952,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "da2550f8-1f35-432e-96de-027cff592bdd"
   },
   "outputs": [],
   "source": [
    "# create input array and Xs , Ys\n",
    "\n",
    "input_mesra = []\n",
    "for mesra in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([mesra])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        broken = token_list[: i + 1]  # broke mesra to word\n",
    "        input_mesra.append(broken)  # gatering words in array of mesra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fc543-8470-4de6-87f7-8346f8532d61",
   "metadata": {
    "id": "219fc543-8470-4de6-87f7-8346f8532d61",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## this will be good for gettingword to labeling\n",
    "# print(input_mesra)\n",
    "# [[1057, 75],\n",
    "# [1057, 75, 1],\n",
    "# [1057, 75, 1, 805],\n",
    "# [1057, 75, 1, 805, 34],\n",
    "# [1057, 75, 1, 805, 34, 1],\n",
    "# [1057, 75, 1, 805, 34, 1, 1526],\n",
    "# [69, 230],\n",
    "# [69, 230, 806],\n",
    "# [69, 230, 806, 1],\n",
    "# [69, 230, 806, 1, 316],\n",
    "# [69, 230, 806, 1, 316, 90],\n",
    "# [69, 230, 806, 1, 316, 90, 2618],\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18375a-ec67-4706-b87c-b8b4a9290307",
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1744557142952,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "7a18375a-ec67-4706-b87c-b8b4a9290307"
   },
   "outputs": [],
   "source": [
    "# pad sequences for unifing length\n",
    "\n",
    "max_mesra = max([len(x) for x in input_mesra])\n",
    "\n",
    "input_mesra = np.array(\n",
    "    keras.preprocessing.sequence.pad_sequences(\n",
    "        sequences=input_mesra,\n",
    "        maxlen=max_mesra,\n",
    "        padding=\"pre\",  # pre padding cause i think its better for labels!.\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ddb80-6590-4df7-a6e3-f90f60a5599b",
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1744557142952,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "009ddb80-6590-4df7-a6e3-f90f60a5599b"
   },
   "outputs": [],
   "source": [
    "# Xs and Ys\n",
    "Xs = input_mesra[:, :-1]\n",
    "Ys = input_mesra[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c8616-961f-4040-bc11-96b56b118059",
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1744557142952,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "8c0c8616-961f-4040-bc11-96b56b118059"
   },
   "outputs": [],
   "source": [
    "# one-hoting ys\n",
    "Ys = keras.utils.to_categorical(x=Ys, num_classes=total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398e2dd-598d-47a8-9205-f03c60737e79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1744557142952,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "b398e2dd-598d-47a8-9205-f03c60737e79",
    "outputId": "1d6fcc6c-2115-4c0d-e6ab-3330a8390d80"
   },
   "outputs": [],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecd744-0f41-4ccd-9d87-80feb669b82a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2701,
     "status": "ok",
     "timestamp": 1744557145649,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "afecd744-0f41-4ccd-9d87-80feb669b82a",
    "outputId": "11130c97-9ebd-48ab-9ca3-793f8d40f7aa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.InputLayer(shape=(18,)))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Embedding(\n",
    "        total_word,\n",
    "        output_dim=100,\n",
    "    )\n",
    ")\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(150, activation=\"relu\")))\n",
    "\n",
    "model.add(keras.layers.Dense(units=total_word, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076aeb61-b28b-4fbe-b28c-5f4c97b3f6aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255943,
     "status": "ok",
     "timestamp": 1744557405763,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "076aeb61-b28b-4fbe-b28c-5f4c97b3f6aa",
    "outputId": "e5580496-bc7e-41c1-ca69-95a105f0423c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#### important NOTE:\n",
    "#### FIT MODEL AS ALWAYS REQUIRED FOR 4 GB of RAM\n",
    "#### WHICH IS NOT AVALABLE IN MY DOCKER CONTAINER\n",
    "#### NEXT CELL WILL REDEASE IT TO ~600 MB\n",
    "\n",
    "history = model.fit(x=Xs, y=Ys, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4334e0e-6b0a-49bf-a9e5-f04c94809a49",
   "metadata": {
    "id": "e4334e0e-6b0a-49bf-a9e5-f04c94809a49",
    "outputId": "12719d19-6c2e-40eb-f447-f34f50f27a92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## NICE JOB DEEPSEEK!!!\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "\n",
    "train_generator = DataGenerator(Xs, Ys, batch_size=128)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12d220-82c9-41ee-97af-0088fe36ef80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9848,
     "status": "ok",
     "timestamp": 1744557415603,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "af12d220-82c9-41ee-97af-0088fe36ef80",
    "outputId": "bb9035c6-b4e8-4252-c074-5b0697f7bcb4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predic\n",
    "input_text = \"گقتم درین سرایم گفنی برخیز ز جایت\"\n",
    "next_words = 90\n",
    "for i in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    token_list = keras.preprocessing.sequence.pad_sequences(\n",
    "        [token_list], maxlen=max_mesra, padding=\"pre\"\n",
    "    )\n",
    "\n",
    "    ## Make predictions\n",
    "    predict = model.predict(token_list, verbose=0)  # too many logs\n",
    "    ## One-hot best results\n",
    "    predicted_classes = np.argmax(predict, axis=1)\n",
    "\n",
    "    output_word = \"\"\n",
    "    # encode to word\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_classes:\n",
    "            output_word = word\n",
    "            break\n",
    "    input_text += \" \" + output_word\n",
    "print(\"\\n\\n\\n\" + input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4386f-7cfd-4eb2-b5b4-5e68d929d355",
   "metadata": {
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1744557596947,
     "user": {
      "displayName": "Matin Nosrati",
      "userId": "16469621278101823226"
     },
     "user_tz": -210
    },
    "id": "e2d4386f-7cfd-4eb2-b5b4-5e68d929d355"
   },
   "outputs": [],
   "source": [
    "# export model\n",
    "model.save(\"manochehri.keras\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
