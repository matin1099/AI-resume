{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cf9c07-9d9e-4cbe-a5d8-de813407ed2d",
   "metadata": {
    "id": "a90300b7-22fe-4e8f-97bc-25f9bfcab982"
   },
   "source": [
    "# Cifar-10 classification from scratch.\n",
    "in this notebook, we will build and train a CNN model on Cifar10 dataset\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0c830-c2ed-4cbb-80cc-bbb6422d8ba2",
   "metadata": {
    "id": "83b2e635-28b4-40e3-a42f-101671e7a2e1"
   },
   "source": [
    "## phase one:\n",
    "### load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0n3PPz7mboW-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40379,
     "status": "ok",
     "timestamp": 1744103747257,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "0n3PPz7mboW-",
    "outputId": "01f1cbf2-925a-4d92-a3de-0a80c725df1e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "%cd /content/drive/MyDrive/Resume/Classification/Cifar10-pure/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4c340-8a90-4a0d-8a9b-b4d11acbd7f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6411,
     "status": "ok",
     "timestamp": 1744103753661,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "87a4c340-8a90-4a0d-8a9b-b4d11acbd7f6",
    "outputId": "c38c110e-5430-472e-8feb-111550174807"
   },
   "outputs": [],
   "source": [
    "# Load librarys and the TensorBoard notebook extension\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "# clean log dir\n",
    "!rm -rf logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6cb82-b58c-48fb-b869-fbc67d9f73bb",
   "metadata": {
    "id": "3ec6cb82-b58c-48fb-b869-fbc67d9f73bb",
    "scrolled": true
   },
   "source": [
    "## phase two:\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7f990-e88e-4aee-a7e7-104fdb6ff32d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6800,
     "status": "ok",
     "timestamp": 1744103760447,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "aeb7f990-e88e-4aee-a7e7-104fdb6ff32d",
    "outputId": "a34b62c8-a043-4486-c00c-2f0f45f2ac85"
   },
   "outputs": [],
   "source": [
    "# load data and assert the correct number for data\n",
    "## load Cifar10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# checking data shape\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 10)\n",
    "\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_test.shape == (10000, 10)\n",
    "\n",
    "# create val and test set\n",
    "x_val = x_test[:5000]\n",
    "x_test = x_test[5000:]\n",
    "y_val = y_test[:5000]\n",
    "y_test = y_test[5000:]\n",
    "\n",
    "# checking data shape\n",
    "assert x_val.shape == (5000, 32, 32, 3)\n",
    "assert y_val.shape == (5000, 10)\n",
    "\n",
    "assert x_test.shape == (5000, 32, 32, 3)\n",
    "assert y_test.shape == (5000, 10)\n",
    "map2name = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6008009-4565-424e-bdde-1f2f4d74eff6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1744103760447,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "e6008009-4565-424e-bdde-1f2f4d74eff6",
    "outputId": "cf813c47-3f03-4be6-f60b-e62b368bdb27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Visualize some sample\n",
    "\n",
    "f, axarr = plt.subplots(2, 2)\n",
    "axarr[0, 0].imshow(x_train[5])\n",
    "axarr[0, 0].set_title(f\"label is {map2name.get(y_train[5].argmax())}\")\n",
    "axarr[0, 1].imshow(x_train[50])\n",
    "axarr[0, 1].set_title(f\"label is {map2name.get(y_train[50].argmax())}\")\n",
    "\n",
    "axarr[1, 0].imshow(x_train[500])\n",
    "axarr[1, 0].set_title(f\"label is {map2name.get(y_train[500].argmax())}\")\n",
    "\n",
    "axarr[1, 1].imshow(x_train[5000])\n",
    "axarr[1, 1].set_title(f\"label is {map2name.get(y_train[5000].argmax())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14188f-0154-4a48-82ac-b120f50f3e0b",
   "metadata": {
    "id": "2a14188f-0154-4a48-82ac-b120f50f3e0b"
   },
   "source": [
    "## phase Three:\n",
    "### create model\n",
    " 1.  we will use panda method.\n",
    " 2. would use augmention\n",
    " 3. would use CNN for featur extraction\n",
    " 4. would use Dense for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45142d43-9cbb-4d2f-80be-bfe1c303a478",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2360,
     "status": "ok",
     "timestamp": 1744103762795,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "45142d43-9cbb-4d2f-80be-bfe1c303a478",
    "outputId": "516494e2-2746-4b8e-900f-76ca61e561aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 16:05:11.045555: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-20 16:05:11.073565: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-20 16:05:11.127075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745165111.182471      18 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745165111.198671      18 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745165111.344927      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745165111.344963      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745165111.344968      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745165111.344972      18 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# prepare layers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Define data augmentation pipeline\u001b[39;00m\n\u001b[32m      6\u001b[39m data_augmentation = keras.Sequential(\n\u001b[32m      7\u001b[39m     [\n\u001b[32m      8\u001b[39m         keras.layers.RandomFlip(\u001b[33m\"\u001b[39m\u001b[33mhorizontal\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ]\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/pywrap_tensorflow.py:37\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mself_check\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[32m     43\u001b[39m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/self_check.py:63\u001b[39m, in \u001b[36mpreload_check\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     50\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     51\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m. TensorFlow requires that these DLLs \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[33mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m           % \u001b[33m\"\u001b[39m\u001b[33m or \u001b[39m\u001b[33m\"\u001b[39m.join(missing))\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[32m     60\u001b[39m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[32m     61\u001b[39m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[32m     62\u001b[39m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[32m     64\u001b[39m   _pywrap_cpu_feature_guard.InfoAboutUnusedCPUFeatures()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# prepare layers\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define data augmentation pipeline\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.15),  # Increased rotation range\n",
    "        keras.layers.RandomZoom(0.2),  # More aggressive zoom\n",
    "        keras.layers.RandomContrast(0.1),  # New: Helps with lighting variations\n",
    "    ]\n",
    ")\n",
    "# CNN + Classi fire\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((32, 32, 3)),\n",
    "        data_augmentation,\n",
    "        keras.layers.Rescaling(1.0 / 255),\n",
    "        # Block 1 (32 filters)\n",
    "        keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D((2, 2)),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        # Block 2 (64 filters)\n",
    "        keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D((2, 2)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        # Block 3 (128 filters)\n",
    "        keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        # Classifier\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff988c-fda9-4ff6-a41c-acb6b69ddde1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1744103764873,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "28ff988c-fda9-4ff6-a41c-acb6b69ddde1",
    "outputId": "59fbf2e6-ac20-45fd-c5de-fbc716fb697f"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618cbc2-07fc-4c6d-b99f-9a4aee1ed2c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1744103764873,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "8618cbc2-07fc-4c6d-b99f-9a4aee1ed2c7"
   },
   "outputs": [],
   "source": [
    "# Compile  model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9cd0c6-43e4-4f0c-a447-c569e254b163",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1744103764873,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "ca9cd0c6-43e4-4f0c-a447-c569e254b163"
   },
   "outputs": [],
   "source": [
    "# custom call  back for +80 percent acc\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"Halts the training when the accuravy rise  above 90%\n",
    "\n",
    "        Args:\n",
    "            epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "            logs (dict) - metric results from the training epoch\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the loss\n",
    "        if logs[\"categorical_accuracy\"] > 80:\n",
    "\n",
    "            # Stop if threshold is met\n",
    "            print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3010f98-1cb8-418f-ae32-14e05e9aad35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3409321,
     "status": "ok",
     "timestamp": 1744107174844,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "a3010f98-1cb8-418f-ae32-14e05e9aad35",
    "outputId": "f948b1cc-4d7c-4dbf-ac67-6027ea02562a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[\n",
    "        myCallback(),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0d714-b0c5-4145-bd2c-86a7b01fdc01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1744107176086,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "68b0d714-b0c5-4145-bd2c-86a7b01fdc01",
    "outputId": "846838b0-ea44-4157-8cda-dd9792a3162e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model performance on the test set\n",
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G5WK_FmteJmd",
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1744107174846,
     "user": {
      "displayName": "anisa nosraty",
      "userId": "01169053488001909703"
     },
     "user_tz": -210
    },
    "id": "G5WK_FmteJmd"
   },
   "outputs": [],
   "source": [
    "# export model\n",
    "model.save(\"Cifar10-pure.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de38e4d-9bb0-4efc-b368-a538da0992e4",
   "metadata": {
    "id": "4de38e4d-9bb0-4efc-b368-a538da0992e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --bind_all --logdir logs  --port 7776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eX1tIz4fkug_",
   "metadata": {
    "id": "eX1tIz4fkug_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
