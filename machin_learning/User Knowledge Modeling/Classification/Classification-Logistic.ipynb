{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12291e8b-fa05-43c4-b1c8-fc8ee1434436",
   "metadata": {},
   "source": [
    "# رویکرد مناسبی نبود\n",
    "\n",
    "# Classification Approch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382ceda6-2577-40cf-af60-b8a27b6a02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "ConfusionMatrixDisplay,PrecisionRecallDisplay,RocCurveDisplay)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Model(s)\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d9d54-2169-4f1a-a2e5-84825d25d13e",
   "metadata": {},
   "source": [
    "## Work flow\n",
    "0. [ ] Clean and Engeering Data for X and y\n",
    "1. [ ] Split Data in Train/Test for X and y\n",
    "2. [ ] Scaler on Training X & X test\n",
    "3. [ ] Create Model(s)\n",
    "4. [ ] Create Pipeline and HyperParameters\n",
    "5. [ ] Fit/Train Model(s) on X Train\n",
    "6. [ ] Evaluate Model(s) on X test\n",
    "7. [ ] Adjust Param as Necessary\n",
    "8. [ ] Bonus: Save Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e942b-4aa1-4cce-a20f-d21389ca4b4d",
   "metadata": {},
   "source": [
    "### PreProcess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de3f6d-8ba5-4f71-a346-cbe315f3b80d",
   "metadata": {},
   "source": [
    "#### Clean and Engeering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59062e44-47b1-4d67-b2d2-b8353f079e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 258 entries, 0 to 257\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   STG     258 non-null    float64\n",
      " 1   SCG     258 non-null    float64\n",
      " 2   STR     258 non-null    float64\n",
      " 3   LPR     258 non-null    float64\n",
      " 4   PEG     258 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 10.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145 entries, 0 to 144\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   STG     145 non-null    float64\n",
      " 1   SCG     145 non-null    float64\n",
      " 2   STR     145 non-null    float64\n",
      " 3   LPR     145 non-null    float64\n",
      " 4   PEG     145 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 5.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_excel('../Data_User_Modeling_Dataset_Hamdi Tolga KAHRAMAN.xls',sheet_name='Training_Data')\n",
    "X_test = pd .read_excel('../Data_User_Modeling_Dataset_Hamdi Tolga KAHRAMAN.xls',sheet_name='Test_Data')\n",
    "\n",
    "\n",
    "#### Clean and Engeering Data\n",
    "\n",
    "X_test=X_test.drop(['Attribute Information:'],axis=1)\n",
    "\n",
    "y_train = X_train[' UNS']\n",
    "X_train = X_train.drop([' UNS'], axis=1)\n",
    "\n",
    "\n",
    "y_test = X_test[' UNS']\n",
    "X_test =X_test.drop([' UNS','Unnamed: 6','Unnamed: 7'],axis=1)\n",
    "\n",
    "X_train.info()\n",
    "\n",
    "X_train\n",
    "\n",
    "#OK\n",
    "\n",
    "X_test.info()\n",
    "\n",
    "\n",
    "#OK\n",
    "\n",
    "y_test.value_counts()\n",
    "\n",
    "y_train.value_counts()\n",
    "\n",
    "y_train.value_counts()\n",
    "\n",
    "#need to map\n",
    "vTs={\n",
    "    'Very Low':0,\n",
    "    'very_low':0,\n",
    "    'Low':1,\n",
    "    'Middle':2,\n",
    "    'High':3\n",
    "}\n",
    "y_train = y_train.map(vTs)\n",
    "\n",
    "y_test.value_counts()\n",
    "\n",
    "#need map\n",
    "y_test = y_test.map(vTs)\n",
    "\n",
    "#df['Output']= df['Output'].map({'N':1,'O':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046338d-f8fc-45ad-9881-036fa8a7e110",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ac3c2-c2a2-4052-a880-b84a372e0d27",
   "metadata": {},
   "source": [
    "#### Create Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92747ac3-caac-431f-b12e-fc88cc6135b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a94beee-b124-4318-866e-f027263f44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('log',log)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340eb8f8-6476-4af7-a0de-90181d4a37fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      " |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      " |  that regularization is applied by default**. It can handle both dense\n",
      " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      " |  floats for optimal performance; any other input format will be converted\n",
      " |  (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
      " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
      " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      " |  'saga' solver.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : {'l1', 'l2', 'elasticnet', None}, default='l2'\n",
      " |      Specify the norm of the penalty:\n",
      " |  \n",
      " |      - `None`: no penalty is added;\n",
      " |      - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      " |      - `'l1'`: add a L1 penalty term;\n",
      " |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      " |  \n",
      " |      .. warning::\n",
      " |         Some penalties may not work with some solvers. See the parameter\n",
      " |         `solver` below, to know the compatibility between the penalty and\n",
      " |         solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |         The 'none' option was deprecated in version 1.2, and will be removed\n",
      " |         in 1.4. Use `None` instead.\n",
      " |  \n",
      " |  dual : bool, default=False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default=1\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      " |      data. See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      " |      To choose a solver, you might want to consider the following aspects:\n",
      " |  \n",
      " |          - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      " |            and 'saga' are faster for large ones;\n",
      " |          - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      " |            'lbfgs' handle multinomial loss;\n",
      " |          - 'liblinear' is limited to one-versus-rest schemes.\n",
      " |          - 'newton-cholesky' is a good choice for `n_samples` >> `n_features`,\n",
      " |            especially with one-hot encoded categorical features with rare\n",
      " |            categories. Note that it is limited to binary classification and the\n",
      " |            one-versus-rest reduction for multiclass classification. Be aware that\n",
      " |            the memory usage of this solver has a quadratic dependency on\n",
      " |            `n_features` because it explicitly computes the Hessian matrix.\n",
      " |  \n",
      " |      .. warning::\n",
      " |         The choice of the algorithm depends on the penalty chosen.\n",
      " |         Supported penalties by solver:\n",
      " |  \n",
      " |         - 'lbfgs'           -   ['l2', None]\n",
      " |         - 'liblinear'       -   ['l1', 'l2']\n",
      " |         - 'newton-cg'       -   ['l2', None]\n",
      " |         - 'newton-cholesky' -   ['l2', None]\n",
      " |         - 'sag'             -   ['l2', None]\n",
      " |         - 'saga'            -   ['elasticnet', 'l1', 'l2', None]\n",
      " |  \n",
      " |      .. note::\n",
      " |         'sag' and 'saga' fast convergence is only guaranteed on features\n",
      " |         with approximately the same scale. You can preprocess the data with\n",
      " |         a scaler from :mod:`sklearn.preprocessing`.\n",
      " |  \n",
      " |      .. seealso::\n",
      " |         Refer to the User Guide for more information regarding\n",
      " |         :class:`LogisticRegression` and more specifically the\n",
      " |         :ref:`Table <Logistic_regression>`\n",
      " |         summarizing solver/penalty supports.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |      .. versionadded:: 1.2\n",
      " |         newton-cholesky solver.\n",
      " |  \n",
      " |  max_iter : int, default=100\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  l1_ratio : float, default=None\n",
      " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      " |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes, )\n",
      " |      A list of class labels known to the classifier.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |          :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\n",
      " |          for Non-Strongly Convex Composite Objectives\" <1407.0202>`\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :])\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,) default=None\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict logarithm of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is proportional to the signed\n",
      " |      distance of that sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the confidence scores.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      " |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      " |          this class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the predictions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Vector containing the class labels for each sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5b25f4-ba36-4803-9cca-6ebc7c6bc533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper param value\n",
    "penalty = ['l2']\n",
    "solver = ['liblinear','saga']\n",
    "multi_class = ['multinomial']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b7ef6e-f98d-47e4-87db-b0a0e2f3a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_param ={\n",
    "    'log__penalty':penalty,\n",
    "    'log__solver':solver,\n",
    "    'log__multi_class':multi_class,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf71735-d973-44d5-abfc-8e293edbb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = GridSearchCV(estimator=pipe , param_grid=hyp_param,cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f6ab4-f386-4b39-b2fb-0d64674b9266",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a9a172-45bc-4fca-b802-fb058e1e567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;log&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;log&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('log', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc73c9-09fd-4f02-921f-b7d33127da81",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c08b74-6243-41d4-8313-cecf6a1fb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c60c9-cef4-4ebf-9127-ee39280a5292",
   "metadata": {},
   "source": [
    "#### Test On data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c279979-beba-4ff6-8c7f-0d0abf7117af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fee2c749cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(\n",
    "    y_true=y_test, y_pred=y_pred)\n",
    "                       ,display_labels=full_model.classes_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea40b54-7c30-4e4a-91f1-f0ebd666044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.53      0.89      0.67        46\n",
      "           2       0.80      0.59      0.68        34\n",
      "           3       0.91      1.00      0.95        39\n",
      "\n",
      "    accuracy                           0.69       145\n",
      "   macro avg       0.56      0.62      0.57       145\n",
      "weighted avg       0.60      0.69      0.63       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_pred,\n",
    "                      y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b20bed7-2745-4b78-9aa8-98e26570c9a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log__multi_class': 'multinomial',\n",
       " 'log__penalty': 'l2',\n",
       " 'log__solver': 'saga'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b96fdc-ae0e-4197-8232-d9da2e4687a4",
   "metadata": {},
   "source": [
    "### Final Model(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4fe54-02b3-484f-b998-b033deed4205",
   "metadata": {},
   "source": [
    "#### Train on all Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e33b81-ae1c-437d-98d8-12df18db766a",
   "metadata": {},
   "source": [
    "#### Save with joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58cb9b-3e99-44fa-be8d-290402b9ec34",
   "metadata": {},
   "source": [
    "X = pd.concat([X_train,X_test])\n",
    "y = pd.concat([y_train,y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c61f04-e8a4-4a06-b4a3-76e670253ec3",
   "metadata": {},
   "source": [
    "final_model = SVC(decision_function_shape='ovo',degree=2,gamma='scale',kernel='poly')\n",
    "final_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2c87d-bf06-4930-8109-475e19f1259c",
   "metadata": {},
   "source": [
    "import joblib\n",
    "joblib.dump(value=full_model,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85138d-b4a0-4347-9042-c8f9d818a109",
   "metadata": {},
   "source": [
    "# Congratulations!!!\n",
    "\n",
    "#### Created and trained by  Matin1099.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
