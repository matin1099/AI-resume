{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12291e8b-fa05-43c4-b1c8-fc8ee1434436",
   "metadata": {},
   "source": [
    "# Classification Approch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f88f2-71d5-4299-891d-c33ec1e3ee51",
   "metadata": {},
   "source": [
    "#  رویکرد KNN رویکردی مناسب تری بود\n",
    "## Lineaer\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           N       0.86      0.96      0.91        26\n",
    "           O       0.00      0.00      0.00         4\n",
    "\n",
    "    accuracy                           0.83        30\n",
    "   macro avg       0.43      0.48      0.45        30\n",
    "weighted avg       0.75      0.83      0.79        30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b001b02-ee4c-4559-a969-6a6f14a481ba",
   "metadata": {},
   "source": [
    "## Polynimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10457b3f-95fc-4f3e-8b14-e205bc968bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "ConfusionMatrixDisplay,PrecisionRecallDisplay,RocCurveDisplay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ac17c-3b11-41e3-a399-bfd76306736d",
   "metadata": {},
   "source": [
    "## Work flow\n",
    "0. [X] Clean and Engeering Data for X and y\n",
    "1. [X] Split Data in Train/Test for X and y\n",
    "2. [X] Scaler on Training X & X test\n",
    "3. [x] Create Model(s)\n",
    "4. [x] Fit/Train Model(s) on X Train\n",
    "5. [ ] Evaluate Model(s) on X test\n",
    "6. [ ] Adjust Param as Necessary\n",
    "7. [ ] Bonus: Save Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e942b-4aa1-4cce-a20f-d21389ca4b4d",
   "metadata": {},
   "source": [
    "### PreProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76a6566e-c273-40e9-8e6c-da1a360f9274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Childish diseases</th>\n",
       "      <th>Trauma</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>High fever</th>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Sitting hour/day</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season   Age  Childish diseases  Trauma  Surgical  High fever  \\\n",
       "0    -0.33  0.69                  0       1         1           0   \n",
       "1    -0.33  0.94                  1       0         1           0   \n",
       "2    -0.33  0.50                  1       0         0           0   \n",
       "3    -0.33  0.75                  0       1         1           0   \n",
       "4    -0.33  0.67                  1       1         0           0   \n",
       "..     ...   ...                ...     ...       ...         ...   \n",
       "95   -1.00  0.67                  1       0         0           0   \n",
       "96   -1.00  0.61                  1       0         0           0   \n",
       "97   -1.00  0.67                  1       1         1           0   \n",
       "98   -1.00  0.64                  1       0         1           0   \n",
       "99   -1.00  0.69                  0       1         1           0   \n",
       "\n",
       "    Alcohol consumption  Smoking  Sitting hour/day Output  \n",
       "0                   0.8        0              0.88      N  \n",
       "1                   0.8        1              0.31      O  \n",
       "2                   1.0       -1              0.50      N  \n",
       "3                   1.0       -1              0.38      N  \n",
       "4                   0.8       -1              0.50      O  \n",
       "..                  ...      ...               ...    ...  \n",
       "95                  1.0       -1              0.50      N  \n",
       "96                  0.8        0              0.50      N  \n",
       "97                  1.0       -1              0.31      N  \n",
       "98                  1.0        0              0.19      N  \n",
       "99                  0.6       -1              0.19      N  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Season','Age','Childish diseases','Trauma','Surgical','High fever','Alcohol consumption','Smoking','Sitting hour/day','Output']\n",
    "df= pd.read_csv('../fertility_Diagnosis.txt',names=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de3f6d-8ba5-4f71-a346-cbe315f3b80d",
   "metadata": {},
   "source": [
    "#### Clean and Engeering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adfdfef9-d9bd-4a92-a6ed-176d32875f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Season               100 non-null    float64\n",
      " 1   Age                  100 non-null    float64\n",
      " 2   Childish diseases    100 non-null    int64  \n",
      " 3   Trauma               100 non-null    int64  \n",
      " 4   Surgical             100 non-null    int64  \n",
      " 5   High fever           100 non-null    int64  \n",
      " 6   Alcohol consumption  100 non-null    float64\n",
      " 7   Smoking              100 non-null    int64  \n",
      " 8   Sitting hour/day     100 non-null    float64\n",
      " 9   Output               100 non-null    object \n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce786874-2714-4b90-9fb1-83350dae0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Output']= df['Output'].map({'N':1,'O':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c451c7eb-5733-4b7d-a5f0-2b73b6792e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Childish diseases</th>\n",
       "      <th>Trauma</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>High fever</th>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Sitting hour/day</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season   Age  Childish diseases  Trauma  Surgical  High fever  \\\n",
       "0    -0.33  0.69                  0       1         1           0   \n",
       "1    -0.33  0.94                  1       0         1           0   \n",
       "2    -0.33  0.50                  1       0         0           0   \n",
       "3    -0.33  0.75                  0       1         1           0   \n",
       "4    -0.33  0.67                  1       1         0           0   \n",
       "..     ...   ...                ...     ...       ...         ...   \n",
       "95   -1.00  0.67                  1       0         0           0   \n",
       "96   -1.00  0.61                  1       0         0           0   \n",
       "97   -1.00  0.67                  1       1         1           0   \n",
       "98   -1.00  0.64                  1       0         1           0   \n",
       "99   -1.00  0.69                  0       1         1           0   \n",
       "\n",
       "    Alcohol consumption  Smoking  Sitting hour/day Output  \n",
       "0                   0.8        0              0.88      N  \n",
       "1                   0.8        1              0.31      O  \n",
       "2                   1.0       -1              0.50      N  \n",
       "3                   1.0       -1              0.38      N  \n",
       "4                   0.8       -1              0.50      O  \n",
       "..                  ...      ...               ...    ...  \n",
       "95                  1.0       -1              0.50      N  \n",
       "96                  0.8        0              0.50      N  \n",
       "97                  1.0       -1              0.31      N  \n",
       "98                  1.0        0              0.19      N  \n",
       "99                  0.6       -1              0.19      N  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a11ff-f938-41f4-95d9-42ff0616a7ea",
   "metadata": {},
   "source": [
    "#### Split Data in Train/Test for X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e3a0134-3f34-47ec-a434-03b67ca3d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Output'],axis=1)\n",
    "y = df['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80e48298-06c9-4136-8d5a-2ab0e9c4ec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output\n",
       "N    88\n",
       "O    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1099,stratify=y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046338d-f8fc-45ad-9881-036fa8a7e110",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ac3c2-c2a2-4052-a880-b84a372e0d27",
   "metadata": {},
   "source": [
    "#### Create Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1b19d83-a91b-4d8a-8ab7-ce70995bc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e985d0b1-f576-44fe-88a9-2cadb0aee996",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "rf =RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4eddb92c-6206-4817-aed4-fead8a72c158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      " |      Note: This parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
      " |  \n",
      " |      .. deprecated:: 1.1\n",
      " |          The `\"auto\"` option was deprecated in 1.1 and will be removed\n",
      " |          in 1.3.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      Only available if bootstrap=True.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : DecisionTreeClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      " |  sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
      " |      tree classifiers.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(...)\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "451fcd8e-f348-4d53-a12a-b7d590753e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23989d9c-6bc3-45ea-9991-c096ab4dd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =Pipeline([('scaler',scale),('rf',rf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83677d19-d438-4753-991f-f339b8ba6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "n_estimators = list(range(5,201,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f521ad5-bd5c-4cd7-824a-232258e61a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_par = {'rf__criterion':criterion,\n",
    "           'rf__max_features':max_features,\n",
    "           'rf__n_estimators':n_estimators  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e42ac3a4-4981-4571-8db1-7a8187f445d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e885f135-d3cb-4c26-97a0-4f61c3f22423",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = GridSearchCV(pipe,hyp_par,cv=2,scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f6ab4-f386-4b39-b2fb-0d64674b9266",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c59d1ac2-d330-465f-9ff4-003f8cd1e832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;rf&#x27;, RandomForestClassifier())]),\n",
       "             param_grid={&#x27;rf__criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;rf__max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;rf__n_estimators&#x27;: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
       "                                              15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                              23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                              31, 32, 33, 34, ...]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;rf&#x27;, RandomForestClassifier())]),\n",
       "             param_grid={&#x27;rf__criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;rf__max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;rf__n_estimators&#x27;: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
       "                                              15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                              23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                              31, 32, 33, 34, ...]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;rf&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'rf__criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'rf__max_features': ['sqrt', 'log2', None],\n",
       "                         'rf__n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
       "                                              15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                              23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                              31, 32, 33, 34, ...]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc73c9-09fd-4f02-921f-b7d33127da81",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c60c9-cef4-4ebf-9127-ee39280a5292",
   "metadata": {},
   "source": [
    "#### Test On data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23623c45-141d-4b1f-9789-bdd48d7fee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9871ec8e50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred =full_model.predict(X_test)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_true=y_test,y_pred=y_pred),display_labels=full_model.classes_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68a28fcb-9ab2-480f-b15e-2d8214fa55a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.91      1.00      0.95        29\n",
      "           O       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.95      0.62      0.68        33\n",
      "weighted avg       0.92      0.91      0.88        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c47f6aab-fa14-46c2-80c0-1fab0eed1b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', StandardScaler()),\n",
       "  ('rf', RandomForestClassifier(n_estimators=21))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(),\n",
       " 'rf': RandomForestClassifier(n_estimators=21),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'rf__bootstrap': True,\n",
       " 'rf__ccp_alpha': 0.0,\n",
       " 'rf__class_weight': None,\n",
       " 'rf__criterion': 'gini',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'sqrt',\n",
       " 'rf__max_leaf_nodes': None,\n",
       " 'rf__max_samples': None,\n",
       " 'rf__min_impurity_decrease': 0.0,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__min_samples_split': 2,\n",
       " 'rf__min_weight_fraction_leaf': 0.0,\n",
       " 'rf__n_estimators': 21,\n",
       " 'rf__n_jobs': None,\n",
       " 'rf__oob_score': False,\n",
       " 'rf__random_state': None,\n",
       " 'rf__verbose': 0,\n",
       " 'rf__warm_start': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b96fdc-ae0e-4197-8232-d9da2e4687a4",
   "metadata": {},
   "source": [
    "### Final Model(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4fe54-02b3-484f-b998-b033deed4205",
   "metadata": {},
   "source": [
    "#### Train on all Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986536d-099f-4f96-b919-1b0a255728be",
   "metadata": {},
   "source": [
    "##### no need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e33b81-ae1c-437d-98d8-12df18db766a",
   "metadata": {},
   "source": [
    "#### Save with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "246159c0-2175-45b6-bd52-30c784d4850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be61a43c-1e3d-418f-a0f2-55b334c24870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Random_forest.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(value=full_model,filename='Random_forest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85138d-b4a0-4347-9042-c8f9d818a109",
   "metadata": {},
   "source": [
    "# Congratulations!!!\n",
    "\n",
    "#### Created and trained by  Matin1099.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
