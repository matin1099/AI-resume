{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12291e8b-fa05-43c4-b1c8-fc8ee1434436",
   "metadata": {},
   "source": [
    "# Classification Approch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f88f2-71d5-4299-891d-c33ec1e3ee51",
   "metadata": {},
   "source": [
    "#  رویکرد KNN رویکردی مناسب تری بود\n",
    "## Lineaer\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           N       0.86      0.96      0.91        26\n",
    "           O       0.00      0.00      0.00         4\n",
    "\n",
    "    accuracy                           0.83        30\n",
    "   macro avg       0.43      0.48      0.45        30\n",
    "weighted avg       0.75      0.83      0.79        30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10457b3f-95fc-4f3e-8b14-e205bc968bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "ConfusionMatrixDisplay,PrecisionRecallDisplay,RocCurveDisplay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ac17c-3b11-41e3-a399-bfd76306736d",
   "metadata": {},
   "source": [
    "## Work flow\n",
    "0. [X] Clean and Engeering Data for X and y\n",
    "1. [X] Split Data in Train/Test for X and y\n",
    "2. [X] Scaler on Training X & X test\n",
    "3. [x] Create Model(s)\n",
    "4. [x] Fit/Train Model(s) on X Train\n",
    "5. [ ] Evaluate Model(s) on X test\n",
    "6. [ ] Adjust Param as Necessary\n",
    "7. [ ] Bonus: Save Model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e942b-4aa1-4cce-a20f-d21389ca4b4d",
   "metadata": {},
   "source": [
    "### PreProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a6566e-c273-40e9-8e6c-da1a360f9274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Childish diseases</th>\n",
       "      <th>Trauma</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>High fever</th>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Sitting hour/day</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season   Age  Childish diseases  Trauma  Surgical  High fever  \\\n",
       "0    -0.33  0.69                  0       1         1           0   \n",
       "1    -0.33  0.94                  1       0         1           0   \n",
       "2    -0.33  0.50                  1       0         0           0   \n",
       "3    -0.33  0.75                  0       1         1           0   \n",
       "4    -0.33  0.67                  1       1         0           0   \n",
       "..     ...   ...                ...     ...       ...         ...   \n",
       "95   -1.00  0.67                  1       0         0           0   \n",
       "96   -1.00  0.61                  1       0         0           0   \n",
       "97   -1.00  0.67                  1       1         1           0   \n",
       "98   -1.00  0.64                  1       0         1           0   \n",
       "99   -1.00  0.69                  0       1         1           0   \n",
       "\n",
       "    Alcohol consumption  Smoking  Sitting hour/day Output  \n",
       "0                   0.8        0              0.88      N  \n",
       "1                   0.8        1              0.31      O  \n",
       "2                   1.0       -1              0.50      N  \n",
       "3                   1.0       -1              0.38      N  \n",
       "4                   0.8       -1              0.50      O  \n",
       "..                  ...      ...               ...    ...  \n",
       "95                  1.0       -1              0.50      N  \n",
       "96                  0.8        0              0.50      N  \n",
       "97                  1.0       -1              0.31      N  \n",
       "98                  1.0        0              0.19      N  \n",
       "99                  0.6       -1              0.19      N  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Season','Age','Childish diseases','Trauma','Surgical','High fever','Alcohol consumption','Smoking','Sitting hour/day','Output']\n",
    "df= pd.read_csv('../fertility_Diagnosis.txt',names=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de3f6d-8ba5-4f71-a346-cbe315f3b80d",
   "metadata": {},
   "source": [
    "#### Clean and Engeering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfdfef9-d9bd-4a92-a6ed-176d32875f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Season               100 non-null    float64\n",
      " 1   Age                  100 non-null    float64\n",
      " 2   Childish diseases    100 non-null    int64  \n",
      " 3   Trauma               100 non-null    int64  \n",
      " 4   Surgical             100 non-null    int64  \n",
      " 5   High fever           100 non-null    int64  \n",
      " 6   Alcohol consumption  100 non-null    float64\n",
      " 7   Smoking              100 non-null    int64  \n",
      " 8   Sitting hour/day     100 non-null    float64\n",
      " 9   Output               100 non-null    object \n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce786874-2714-4b90-9fb1-83350dae0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Output']= df['Output'].map({'N':1,'O':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c451c7eb-5733-4b7d-a5f0-2b73b6792e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Childish diseases</th>\n",
       "      <th>Trauma</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>High fever</th>\n",
       "      <th>Alcohol consumption</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Sitting hour/day</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season   Age  Childish diseases  Trauma  Surgical  High fever  \\\n",
       "0    -0.33  0.69                  0       1         1           0   \n",
       "1    -0.33  0.94                  1       0         1           0   \n",
       "2    -0.33  0.50                  1       0         0           0   \n",
       "3    -0.33  0.75                  0       1         1           0   \n",
       "4    -0.33  0.67                  1       1         0           0   \n",
       "..     ...   ...                ...     ...       ...         ...   \n",
       "95   -1.00  0.67                  1       0         0           0   \n",
       "96   -1.00  0.61                  1       0         0           0   \n",
       "97   -1.00  0.67                  1       1         1           0   \n",
       "98   -1.00  0.64                  1       0         1           0   \n",
       "99   -1.00  0.69                  0       1         1           0   \n",
       "\n",
       "    Alcohol consumption  Smoking  Sitting hour/day Output  \n",
       "0                   0.8        0              0.88      N  \n",
       "1                   0.8        1              0.31      O  \n",
       "2                   1.0       -1              0.50      N  \n",
       "3                   1.0       -1              0.38      N  \n",
       "4                   0.8       -1              0.50      O  \n",
       "..                  ...      ...               ...    ...  \n",
       "95                  1.0       -1              0.50      N  \n",
       "96                  0.8        0              0.50      N  \n",
       "97                  1.0       -1              0.31      N  \n",
       "98                  1.0        0              0.19      N  \n",
       "99                  0.6       -1              0.19      N  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a11ff-f938-41f4-95d9-42ff0616a7ea",
   "metadata": {},
   "source": [
    "#### Split Data in Train/Test for X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3a0134-3f34-47ec-a434-03b67ca3d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Output'],axis=1)\n",
    "y = df['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80e48298-06c9-4136-8d5a-2ab0e9c4ec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output\n",
       "N    88\n",
       "O    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1099,stratify=y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046338d-f8fc-45ad-9881-036fa8a7e110",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ac3c2-c2a2-4052-a880-b84a372e0d27",
   "metadata": {},
   "source": [
    "#### Create Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1b19d83-a91b-4d8a-8ab7-ce70995bc66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e985d0b1-f576-44fe-88a9-2cadb0aee996",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eddb92c-6206-4817-aed4-fead8a72c158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientBoostingClassifier in module sklearn.ensemble._gb:\n",
      "\n",
      "class GradientBoostingClassifier(sklearn.base.ClassifierMixin, BaseGradientBoosting)\n",
      " |  GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |  \n",
      " |  Gradient Boosting for classification.\n",
      " |  \n",
      " |  This algorithm builds an additive model in a forward stage-wise fashion; it\n",
      " |  allows for the optimization of arbitrary differentiable loss functions. In\n",
      " |  each stage ``n_classes_`` regression trees are fit on the negative gradient\n",
      " |  of the loss function, e.g. binary or multiclass log loss. Binary\n",
      " |  classification is a special case where only a single regression tree is\n",
      " |  induced.\n",
      " |  \n",
      " |  :class:`sklearn.ensemble.HistGradientBoostingClassifier` is a much faster\n",
      " |  variant of this algorithm for intermediate datasets (`n_samples >= 10_000`).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  loss : {'log_loss', 'deviance', 'exponential'}, default='log_loss'\n",
      " |      The loss function to be optimized. 'log_loss' refers to binomial and\n",
      " |      multinomial deviance, the same as used in logistic regression.\n",
      " |      It is a good choice for classification with probabilistic outputs.\n",
      " |      For loss 'exponential', gradient boosting recovers the AdaBoost algorithm.\n",
      " |  \n",
      " |      .. deprecated:: 1.1\n",
      " |          The loss 'deviance' was deprecated in v1.1 and will be removed in\n",
      " |          version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      " |  \n",
      " |  learning_rate : float, default=0.1\n",
      " |      Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      " |      There is a trade-off between learning_rate and n_estimators.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |  n_estimators : int, default=100\n",
      " |      The number of boosting stages to perform. Gradient boosting\n",
      " |      is fairly robust to over-fitting so a large number usually\n",
      " |      results in better performance.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  subsample : float, default=1.0\n",
      " |      The fraction of samples to be used for fitting the individual base\n",
      " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |      Values must be in the range `(0.0, 1.0]`.\n",
      " |  \n",
      " |  criterion : {'friedman_mse', 'squared_error'}, default='friedman_mse'\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      'friedman_mse' for the mean squared error with improvement score by\n",
      " |      Friedman, 'squared_error' for mean squared error. The default value of\n",
      " |      'friedman_mse' is generally the best as it can provide a better\n",
      " |      approximation in some cases.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, values must be in the range `[2, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`\n",
      " |        will be `ceil(min_samples_split * n_samples)`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, values must be in the range `[1, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`\n",
      " |        will be `ceil(min_samples_leaf * n_samples)`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |      Values must be in the range `[0.0, 0.5]`.\n",
      " |  \n",
      " |  max_depth : int or None, default=3\n",
      " |      Maximum depth of the individual regression estimators. The maximum\n",
      " |      depth limits the number of nodes in the tree. Tune this parameter\n",
      " |      for best performance; the best value depends on the interaction\n",
      " |      of the input variables. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |      If int, values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  init : estimator or 'zero', default=None\n",
      " |      An estimator object that is used to compute the initial predictions.\n",
      " |      ``init`` has to provide :meth:`fit` and :meth:`predict_proba`. If\n",
      " |      'zero', the initial raw predictions are set to zero. By default, a\n",
      " |      ``DummyEstimator`` predicting the classes priors is used.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random seed given to each Tree estimator at each\n",
      " |      boosting iteration.\n",
      " |      In addition, it controls the random permutation of the features at\n",
      " |      each split (see Notes for more details).\n",
      " |      It also controls the random splitting of the training data to obtain a\n",
      " |      validation set if `n_iter_no_change` is not None.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, values must be in the range `[1, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0]` and the features\n",
      " |        considered at each split will be `max(1, int(max_features * n_features_in_))`.\n",
      " |      - If 'auto', then `max_features=sqrt(n_features)`.\n",
      " |      - If 'sqrt', then `max_features=sqrt(n_features)`.\n",
      " |      - If 'log2', then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. If 1 then it prints progress and performance\n",
      " |      once in a while (the more trees the lower the frequency). If greater\n",
      " |      than 1 then it prints progress and performance for every tree.\n",
      " |      Values must be in the range `[0, inf)`.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      Values must be in the range `[2, inf)`.\n",
      " |      If `None`, then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Values must be in the range `(0.0, 1.0)`.\n",
      " |      Only used if ``n_iter_no_change`` is set to an integer.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_iter_no_change : int, default=None\n",
      " |      ``n_iter_no_change`` is used to decide if early stopping will be used\n",
      " |      to terminate training when validation score is not improving. By\n",
      " |      default it is set to None to disable early stopping. If set to a\n",
      " |      number, it will set aside ``validation_fraction`` size of the training\n",
      " |      data as validation and terminate training when validation score is not\n",
      " |      improving in all of the previous ``n_iter_no_change`` numbers of\n",
      " |      iterations. The split is stratified.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the early stopping. When the loss is not improving\n",
      " |      by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
      " |      number), the training stops.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  n_estimators_ : int\n",
      " |      The number of estimators as selected by early stopping (if\n",
      " |      ``n_iter_no_change`` is specified). Otherwise it is set to\n",
      " |      ``n_estimators``.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_improvement_ : ndarray of shape (n_estimators,)\n",
      " |      The improvement in loss (= deviance) on the out-of-bag samples\n",
      " |      relative to the previous iteration.\n",
      " |      ``oob_improvement_[0]`` is the improvement in\n",
      " |      loss of the first stage over the ``init`` estimator.\n",
      " |      Only available if ``subsample < 1.0``\n",
      " |  \n",
      " |  train_score_ : ndarray of shape (n_estimators,)\n",
      " |      The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
      " |      model at iteration ``i`` on the in-bag sample.\n",
      " |      If ``subsample == 1`` this is the deviance on the training data.\n",
      " |  \n",
      " |  loss_ : LossFunction\n",
      " |      The concrete ``LossFunction`` object.\n",
      " |  \n",
      " |      .. deprecated:: 1.1\n",
      " |           Attribute `loss_` was deprecated in version 1.1 and will be\n",
      " |          removed in 1.3.\n",
      " |  \n",
      " |  init_ : estimator\n",
      " |      The estimator that provides the initial predictions.\n",
      " |      Set via the ``init`` argument or ``loss.init_estimator``.\n",
      " |  \n",
      " |  estimators_ : ndarray of DecisionTreeRegressor of             shape (n_estimators, ``loss_.K``)\n",
      " |      The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
      " |      classification, otherwise n_classes.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_classes_ : int\n",
      " |      The number of classes.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  HistGradientBoostingClassifier : Histogram-based Gradient Boosting\n",
      " |      Classification Tree.\n",
      " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      " |  RandomForestClassifier : A meta-estimator that fits a number of decision\n",
      " |      tree classifiers on various sub-samples of the dataset and uses\n",
      " |      averaging to improve the predictive accuracy and control over-fitting.\n",
      " |  AdaBoostClassifier : A meta-estimator that begins by fitting a classifier\n",
      " |      on the original dataset and then fits additional copies of the\n",
      " |      classifier on the same dataset where the weights of incorrectly\n",
      " |      classified instances are adjusted such that subsequent classifiers\n",
      " |      focus more on difficult cases.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      " |  \n",
      " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
      " |  \n",
      " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
      " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  The following example shows how to fit a gradient boosting classifier with\n",
      " |  100 decision stumps as weak learners.\n",
      " |  \n",
      " |  >>> from sklearn.datasets import make_hastie_10_2\n",
      " |  >>> from sklearn.ensemble import GradientBoostingClassifier\n",
      " |  \n",
      " |  >>> X, y = make_hastie_10_2(random_state=0)\n",
      " |  >>> X_train, X_test = X[:2000], X[2000:]\n",
      " |  >>> y_train, y_test = y[:2000], y[2000:]\n",
      " |  \n",
      " |  >>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
      " |  ...     max_depth=1, random_state=0).fit(X_train, y_train)\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.913...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostingClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseGradientBoosting\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray of shape (n_samples, n_classes) or (n_samples,)\n",
      " |          The decision function of the input samples, which corresponds to\n",
      " |          the raw values predicted from the trees of the ensemble . The\n",
      " |          order of the classes corresponds to that in the attribute\n",
      " |          :term:`classes_`. Regression and binary classification produce an\n",
      " |          array of shape (n_samples,).\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |  \n",
      " |  staged_decision_function(self, X)\n",
      " |      Compute decision function of ``X`` for each iteration.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      score : generator of ndarray of shape (n_samples, k)\n",
      " |          The decision function of the input samples, which corresponds to\n",
      " |          the raw values predicted from the trees of the ensemble . The\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |          Regression and binary classification are special cases with\n",
      " |          ``k == 1``, otherwise ``k==n_classes``.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Predict class at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  staged_predict_proba(self, X)\n",
      " |      Predict class probabilities at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the ensemble to X, return leaf indices.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
      " |          be converted to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples, n_estimators, n_classes)\n",
      " |          For each datapoint x in X and for each tree in the ensemble,\n",
      " |          return the index of the leaf x ends up in each estimator.\n",
      " |          In the case of binary classification n_classes is 1.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
      " |      Fit the gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (strings or integers in classification, real numbers\n",
      " |          in regression)\n",
      " |          For classification, labels must correspond to classes.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      monitor : callable, default=None\n",
      " |          The monitor is called after each iteration with the current\n",
      " |          iteration, a reference to the estimator and the local variables of\n",
      " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
      " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
      " |          is stopped. The monitor can be used for various things such as\n",
      " |          computing held-out estimates, early stopping, model introspect, and\n",
      " |          snapshoting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  loss_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "451fcd8e-f348-4d53-a12a-b7d590753e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'log_loss',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83677d19-d438-4753-991f-f339b8ba6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(range(1,101,1))\n",
    "max_features = [1.0, 'sqrt', 'log2']\n",
    "criterion = ['friedman_mse', 'squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23989d9c-6bc3-45ea-9991-c096ab4dd080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =Pipeline([('gbc',gbc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f521ad5-bd5c-4cd7-824a-232258e61a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_par = {'gbc__criterion' : criterion,\n",
    " 'gbc__max_features': max_features,\n",
    " 'gbc__n_estimators': n_estimators,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e42ac3a4-4981-4571-8db1-7a8187f445d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e885f135-d3cb-4c26-97a0-4f61c3f22423",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = GridSearchCV(pipe,hyp_par,cv=2,scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f6ab4-f386-4b39-b2fb-0d64674b9266",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c59d1ac2-d330-465f-9ff4-003f8cd1e832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;gbc&#x27;, GradientBoostingClassifier())]),\n",
       "             param_grid={&#x27;gbc__criterion&#x27;: [&#x27;friedman_mse&#x27;, &#x27;squared_error&#x27;],\n",
       "                         &#x27;gbc__max_features&#x27;: [1.0, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;gbc__n_estimators&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                               11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                               19, 20, 21, 22, 23, 24, 25, 26,\n",
       "                                               27, 28, 29, 30, ...]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;gbc&#x27;, GradientBoostingClassifier())]),\n",
       "             param_grid={&#x27;gbc__criterion&#x27;: [&#x27;friedman_mse&#x27;, &#x27;squared_error&#x27;],\n",
       "                         &#x27;gbc__max_features&#x27;: [1.0, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;gbc__n_estimators&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                               11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                               19, 20, 21, 22, 23, 24, 25, 26,\n",
       "                                               27, 28, 29, 30, ...]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gbc&#x27;, GradientBoostingClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('gbc', GradientBoostingClassifier())]),\n",
       "             param_grid={'gbc__criterion': ['friedman_mse', 'squared_error'],\n",
       "                         'gbc__max_features': [1.0, 'sqrt', 'log2'],\n",
       "                         'gbc__n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                               11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                               19, 20, 21, 22, 23, 24, 25, 26,\n",
       "                                               27, 28, 29, 30, ...]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc73c9-09fd-4f02-921f-b7d33127da81",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c60c9-cef4-4ebf-9127-ee39280a5292",
   "metadata": {},
   "source": [
    "#### Test On data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23623c45-141d-4b1f-9789-bdd48d7fee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f53b32ece50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred =full_model.predict(X_test)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_true=y_test,y_pred=y_pred),display_labels=full_model.classes_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d495c1f-77ac-4fd0-ae51-4d84702e0e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f798760add0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred =full_model.predict(X_test)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_true=y_test,y_pred=y_pred),display_labels=full_model.classes_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68a28fcb-9ab2-480f-b15e-2d8214fa55a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.90      1.00      0.95        26\n",
      "           O       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.95      0.62      0.67        30\n",
      "weighted avg       0.91      0.90      0.87        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test,y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c47f6aab-fa14-46c2-80c0-1fab0eed1b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('abc', AdaBoostClassifier(algorithm='SAMME', n_estimators=1))],\n",
       " 'verbose': False,\n",
       " 'abc': AdaBoostClassifier(algorithm='SAMME', n_estimators=1),\n",
       " 'abc__algorithm': 'SAMME',\n",
       " 'abc__base_estimator': 'deprecated',\n",
       " 'abc__estimator': None,\n",
       " 'abc__learning_rate': 1.0,\n",
       " 'abc__n_estimators': 1,\n",
       " 'abc__random_state': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b96fdc-ae0e-4197-8232-d9da2e4687a4",
   "metadata": {},
   "source": [
    "### Final Model(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4fe54-02b3-484f-b998-b033deed4205",
   "metadata": {},
   "source": [
    "#### Train on all Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986536d-099f-4f96-b919-1b0a255728be",
   "metadata": {},
   "source": [
    "##### no need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e33b81-ae1c-437d-98d8-12df18db766a",
   "metadata": {},
   "source": [
    "#### Save with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "246159c0-2175-45b6-bd52-30c784d4850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be61a43c-1e3d-418f-a0f2-55b334c24870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gradiant_boost.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(value=full_model,filename='Gradiant_boost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85138d-b4a0-4347-9042-c8f9d818a109",
   "metadata": {},
   "source": [
    "# Congratulations!!!\n",
    "\n",
    "#### Created and trained by  Matin1099.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
